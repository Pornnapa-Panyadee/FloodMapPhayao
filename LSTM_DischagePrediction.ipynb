{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_DischagePrediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SetUp"
      ],
      "metadata": {
        "id": "2m8GL3C6IKB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOrQWv5ZH-Ri"
      },
      "outputs": [],
      "source": [
        "from pandas import read_csv\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from google.colab import files\n",
        "\n",
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Data"
      ],
      "metadata": {
        "id": "YlJRMqRrIOKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "RucrcmLzmdtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load dataset\n",
        "dataset = read_csv('DataSetWater.csv', header=0, index_col=0)\n",
        "dataset = dataset.drop(columns=['Q25(t)','Q25(t-1)','Q25(t-2)','Q25(t-3)','Q25(t-4)','Rain25'])\n",
        "values = dataset.values\n",
        "# specify columns to plot\n",
        "groups = [0, 1, 2, 3,4,5]\n",
        "i = 1\n",
        "# plot each column\n",
        "pyplot.figure()\n",
        "for group in groups:\n",
        "\tpyplot.subplot(len(groups), 1, i)\n",
        "\tpyplot.plot(values[:, group])\n",
        "\tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
        "\ti += 1\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "EHD1ybmgIM09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode direction\n",
        "encoder = LabelEncoder()\n",
        "values[:,5] = encoder.fit_transform(values[:,5])\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# frame as supervised learning\n",
        "reframed4h = series_to_supervised(scaled, 1, 4)\n",
        "\n",
        "# drop columns we don't want to predict \n",
        "\n",
        "reframed4h.drop(reframed4.columns[[6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29]], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "V7uOznnIIXRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data to Train and Test"
      ],
      "metadata": {
        "id": "y0H13EMuIfHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reframed=reframed4h"
      ],
      "metadata": {
        "id": "bQgDx7TXpgju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
        "\tX, y = train[:, 0:-1], train[:, -1]\n",
        "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
        "\tmodel.add(Dense(1))\n",
        "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "\tfor i in range(nb_epoch):\n",
        "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
        "\t\tmodel.reset_states()\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "-Lr5tF1hXw2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = reframed.values\n",
        "n_train_hours = int(len(reframed)*0.8)\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]\n",
        "  # reshape input to be 3D [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))"
      ],
      "metadata": {
        "id": "OHd6fbF1F1EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeats = 1\n",
        "error_MAPE_train = list()\n",
        "error_MAPE_test = list()\n",
        "error_rmse_train = list()\n",
        "error_rmse_test = list()\n",
        "model_list = list()\n",
        "output_train=pd.DataFrame(train_y)\n",
        "output_test=pd.DataFrame(test_y)"
      ],
      "metadata": {
        "id": "H3DXToqFE_lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for r in range(repeats):\n",
        "  # lstm_model = fit_lstm(train, 1, 100, 6)\n",
        "  # -----------------------------------------------------------------------\n",
        "  values = reframed.values\n",
        "  # -----------------------------------------------------------------------\n",
        "  n_train_hours = int(len(reframed)*0.8)\n",
        "  train = values[:n_train_hours, :]\n",
        "  test = values[n_train_hours:, :]\n",
        "  # split into input and outputs\n",
        "  train_X, train_y = train[:, :-1], train[:, -1]\n",
        "  test_X, test_y = test[:, :-1], test[:, -1]\n",
        "  # reshape input to be 3D [samples, timesteps, features]\n",
        "  train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "  test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
        "  print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  model.add(Dense(units=1, activation='linear'))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  # fit network\n",
        "  history = model.fit(train_X, train_y, epochs=50, batch_size=128, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "\n",
        "  model_list.append(model)\n",
        "  \n",
        "\n",
        "  # make Train\n",
        "  yhat = model.predict(train_X)\n",
        "  train_X = train_X.reshape((train_X.shape[0], train_X.shape[2]))\n",
        "  # invert scaling for forecast\n",
        "  inv_yhat_train = concatenate((yhat, train_X), axis=1)\n",
        "  inv_yhat_train = scaler.inverse_transform(inv_yhat_train)\n",
        "  inv_yhat_train = inv_yhat_train[:,0]\n",
        "  \n",
        "  # invert scaling for actual\n",
        "  train_y = train_y.reshape((len(train_y), 1))\n",
        "  inv_y_train = concatenate((train_y, train_X[:, 1:]), axis=1)\n",
        "  inv_y_train = scaler.inverse_transform(inv_y_train)\n",
        "  inv_y_train = inv_y_train[:,0]\n",
        "  # calculate RMSE\n",
        "  # print(inv_y_train)\n",
        "  output_train[r+1]=pd.DataFrame(inv_yhat_train)\n",
        "  \n",
        "  rmse_train = sqrt(mean_squared_error(inv_y_train, inv_yhat_train))\n",
        "  MAPE_train=mean_absolute_percentage_error(inv_y_train, inv_yhat_train)*100\n",
        "  # -----------------------------------------------------------------------\n",
        "  print(\"===========================================>\", r )\n",
        "  # -----------------------------------------------------------------------\n",
        "\n",
        "  # make a prediction\n",
        "  yhat = model.predict(test_X)\n",
        "  test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
        "  # invert scaling for forecast\n",
        "  inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
        "  inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "  inv_yhat = inv_yhat[:,0]\n",
        "  # invert scaling for actual\n",
        "  test_y = test_y.reshape((len(test_y), 1))\n",
        "  inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
        "  inv_y = scaler.inverse_transform(inv_y)\n",
        "  inv_y = inv_y[:,0]\n",
        "  output_test[r+1]=pd.DataFrame(inv_yhat)\n",
        "  # calculate RMSE\n",
        "  rmse_test = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "  MAPE_test=mean_absolute_percentage_error(inv_y, inv_yhat)*100\n",
        "\n",
        "  error_MAPE_train.append(MAPE_train)\n",
        "  error_MAPE_test.append(MAPE_test)\n",
        "  error_rmse_train.append(rmse_train)\n",
        "  error_rmse_test.append(rmse_test)\n",
        "\n",
        "\n",
        "output_train[\"real\"]=pd.DataFrame(inv_y_train)\n",
        "output_test[\"real\"]=pd.DataFrame(inv_y)\n",
        "                                                                                     "
      ],
      "metadata": {
        "id": "y1sAcafeIh_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " error_MAPE_train"
      ],
      "metadata": {
        "id": "5a_Kv4TPZHXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make File to keep the output"
      ],
      "metadata": {
        "id": "m1bp06B6c2Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_error = pd.DataFrame(error_MAPE_train)\n",
        "output_error.to_csv('output26_error_500_t4.csv')"
      ],
      "metadata": {
        "id": "sBodWE1aX9Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "results = DataFrame()\n",
        "results['MAPE'] = error_MAPE_train\n",
        "print(results.describe())\n",
        "results.boxplot()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "JLdoUrn3ZK1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_train.to_csv('output_train_sti26_500_t4.csv')\n",
        "output_test.to_csv('output_test_sti26_500_t4.csv')"
      ],
      "metadata": {
        "id": "HvIq2_4ANbIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model_list[3].save('model_best26_t4.h5')"
      ],
      "metadata": {
        "id": "zakEcKz-Wn0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = load_model('model_best25.h5')"
      ],
      "metadata": {
        "id": "9zr_HYqjW4Qz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}